// offlineVoice.js
import { pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';

let transcriber = null;
let isModelReady = false;

// åˆå§‹åŒ– Whisper æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
export async function initOfflineVoice() {
  if (isModelReady) return;
  console.log('ğŸ”„ æ­£åœ¨åŠ è½½ç¦»çº¿è¯­éŸ³æ¨¡å‹...');
  transcriber = await pipeline(
    'automatic-speech-recognition',
    'Xenova/whisper-tiny' // å°å·§æ¨¡å‹ï¼Œé€‚åˆç¦»çº¿
  );
  isModelReady = true;
  console.log('âœ… ç¦»çº¿è¯­éŸ³æ¨¡å‹åŠ è½½å®Œæˆ');
}

// è¯†åˆ«éŸ³é¢‘ Blobï¼ˆæ¥è‡ªéº¦å…‹é£ï¼‰
export async function recognizeOffline(audioBlob) {
  if (!isModelReady) await initOfflineVoice();
  try {
    const result = await transcriber(audioBlob);
    return result.text.trim();
  } catch (err) {
    console.error('âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥', err);
    return '';
  }
}